{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Financial Trend Prediction Analysis\n",
    "\n",
    "This notebook demonstrates how to build a machine learning model to predict stock price movements using technical indicators.\n",
    "\n",
    "## 1. Setup and Data Acquisition\n",
    "\n",
    "First, let's import the necessary libraries and fetch historical stock data.\n",
    "\n",
    "```python\n",
    "# Plot the closing price\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(aapl_data['Date'], aapl_data['Close'])\n",
    "plt.title('AAPL Stock Price History')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price ($)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate daily returns\n",
    "aapl_data['Daily_Return'] = aapl_data['Close'].pct_change() * 100\n",
    "\n",
    "# Plot daily returns\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(aapl_data['Date'], aapl_data['Daily_Return'])\n",
    "plt.title('AAPL Daily Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Daily Return (%)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of daily returns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(aapl_data['Daily_Return'].dropna(), kde=True, bins=50)\n",
    "plt.title('Distribution of Daily Returns')\n",
    "plt.xlabel('Daily Return (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Volume analysis\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(aapl_data['Date'], aapl_data['Volume'], alpha=0.5)\n",
    "plt.title('AAPL Trading Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate monthly average\n",
    "monthly_data = aapl_data.set_index('Date').resample('M').mean()\n",
    "\n",
    "# Plot monthly average price\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(monthly_data.index, monthly_data['Close'])\n",
    "plt.title('AAPL Monthly Average Close Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Close Price ($)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## 3. Feature Engineering\n",
    "\n",
    "Now let's calculate various technical indicators to use as features for our model.\n",
    "\n",
    "```python\n",
    "def calculate_technical_indicators(df):\n",
    "    \"\"\"Calculate various technical indicators for stock price data.\"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Simple Moving Averages\n",
    "    data['SMA_5'] = data['Close'].rolling(window=5).mean()\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # Exponential Moving Averages\n",
    "    data['EMA_5'] = data['Close'].ewm(span=5, adjust=False).mean()\n",
    "    data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA_20'] = data['Close'].ewm(span=20, adjust=False).mean()\n",
    "    \n",
    "    # Bollinger Bands (20-day, 2 standard deviations)\n",
    "    data['BB_middle'] = data['Close'].rolling(window=20).mean()\n",
    "    data['BB_std'] = data['Close'].rolling(window=20).std()\n",
    "    data['BB_upper'] = data['BB_middle'] + 2 * data['BB_std']\n",
    "    data['BB_lower'] = data['BB_middle'] - 2 * data['BB_std']\n",
    "    data['BB_width'] = (data['BB_upper'] - data['BB_lower']) / data['BB_middle']\n",
    "    \n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    data['EMA_12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "    data['EMA_26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "    data['MACD'] = data['EMA_12'] - data['EMA_26']\n",
    "    data['MACD_signal'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    data['MACD_hist'] = data['MACD'] - data['MACD_signal']\n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    delta = data['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    \n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    \n",
    "    # Handle division by zero\n",
    "    rs = avg_gain / avg_loss.replace(0, np.finfo(float).eps)\n",
    "    data['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Momentum\n",
    "    data['Momentum_5'] = data['Close'] / data['Close'].shift(5) - 1\n",
    "    data['Momentum_10'] = data['Close'] / data['Close'].shift(10) - 1\n",
    "    data['Momentum_20'] = data['Close'] / data['Close'].shift(20) - 1\n",
    "    \n",
    "    # Price Rate of Change\n",
    "    data['ROC_5'] = (data['Close'] - data['Close'].shift(5)) / data['Close'].shift(5) * 100\n",
    "    data['ROC_10'] = (data['Close'] - data['Close'].shift(10)) / data['Close'].shift(10) * 100\n",
    "    \n",
    "    # Volume-based indicators\n",
    "    data['Volume_SMA_5'] = data['Volume'].rolling(window=5).mean()\n",
    "    data['Volume_SMA_10'] = data['Volume'].rolling(window=10).mean()\n",
    "    data['Volume_Change'] = data['Volume'] / data['Volume'].shift(1) - 1\n",
    "    \n",
    "    # Price to Volume Ratio\n",
    "    data['Price_Volume_Ratio'] = data['Close'] / (data['Volume'] + 1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Calculate technical indicators\n",
    "aapl_features = calculate_technical_indicators(aapl_data)\n",
    "\n",
    "# Create target variable: 1 if price goes up next day, 0 otherwise\n",
    "aapl_features['Target'] = (aapl_features['Close'].shift(-1) > aapl_features['Close']).astype(int)\n",
    "\n",
    "# Display features with technical indicators\n",
    "aapl_features.tail()\n",
    "\n",
    "# Plot some technical indicators\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot closing price with moving averages\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(aapl_features['Date'], aapl_features['Close'], label='Close')\n",
    "plt.plot(aapl_features['Date'], aapl_features['SMA_20'], label='SMA 20')\n",
    "plt.plot(aapl_features['Date'], aapl_features['SMA_50'], label='SMA 50')\n",
    "plt.title('Closing Price with Moving Averages')\n",
    "plt.legend()\n",
    "\n",
    "# Plot RSI\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(aapl_features['Date'], aapl_features['RSI'])\n",
    "plt.axhline(y=70, color='r', linestyle='-', alpha=0.3)\n",
    "plt.axhline(y=30, color='g', linestyle='-', alpha=0.3)\n",
    "plt.title('Relative Strength Index (RSI)')\n",
    "\n",
    "# Plot MACD\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(aapl_features['Date'], aapl_features['MACD'], label='MACD')\n",
    "plt.plot(aapl_features['Date'], aapl_features['MACD_signal'], label='Signal')\n",
    "plt.bar(aapl_features['Date'], aapl_features['MACD_hist'], label='Histogram', alpha=0.3)\n",
    "plt.title('MACD')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## 4. Data Preparation\n",
    "\n",
    "Let's prepare the data for model training.\n",
    "\n",
    "```python\n",
    "# Drop NaN values and unwanted columns\n",
    "aapl_features_clean = aapl_features.dropna()\n",
    "\n",
    "# Drop columns that shouldn't be used as features\n",
    "features_to_drop = ['Date', 'Target', 'Adj Close']\n",
    "X = aapl_features_clean.drop(features_to_drop, axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = aapl_features_clean['Target']\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=feature_names)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Testing target shape: {y_test.shape}\")\n",
    "```\n",
    "\n",
    "## 5. Model Training and Evaluation\n",
    "\n",
    "Now we'll train a Gradient Boosting Classifier and evaluate its performance.\n",
    "\n",
    "```python\n",
    "# Create and train model\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_model.predict(X_test)\n",
    "y_prob = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## 6. Feature Importance\n",
    "\n",
    "Let's examine which features are most important for our prediction.\n",
    "\n",
    "```python\n",
    "# Get feature importances\n",
    "importances = gb_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(range(len(importances)), importances[indices])\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top 10 features\n",
    "print(\"Top 10 most important features:\")\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
    "```\n",
    "\n",
    "## 7. Hyperparameter Tuning\n",
    "\n",
    "Let's optimize our model using grid search.\n",
    "\n",
    "```python\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Setup grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "print(\"Performing grid search for hyperparameter optimization...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best F1 score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate optimized model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"\\nOptimized Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_best):.4f}\")\n",
    "```\n",
    "\n",
    "## 8. Model Visualization and Interpretation\n",
    "\n",
    "Let's visualize our model's predictions over time.\n",
    "\n",
    "```python\n",
    "# Get predictions for the entire dataset\n",
    "X_full = pd.DataFrame(scaler.transform(X), columns=feature_names)\n",
    "y_full_pred = best_model.predict(X_full)\n",
    "y_full_prob = best_model.predict_proba(X_full)[:, 1]\n",
    "\n",
    "# Add predictions to the original dataframe\n",
    "aapl_features_clean['Predicted_Target'] = y_full_pred\n",
    "aapl_features_clean['Predicted_Probability'] = y_full_prob\n",
    "\n",
    "# Calculate cumulative returns\n",
    "aapl_features_clean['Actual_Return'] = aapl_features_clean['Close'].pct_change()\n",
    "aapl_features_clean['Actual_Cumulative_Return'] = (1 + aapl_features_clean['Actual_Return']).cumprod() - 1\n",
    "\n",
    "# Simulated trading strategy\n",
    "aapl_features_clean['Strategy_Return'] = aapl_features_clean['Actual_Return'].shift(-1) * (aapl_features_clean['Predicted_Target'] * 2 - 1)\n",
    "aapl_features_clean['Strategy_Cumulative_Return'] = (1 + aapl_features_clean['Strategy_Return'].fillna(0)).cumprod() - 1\n",
    "\n",
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(aapl_features_clean['Date'], aapl_features_clean['Actual_Cumulative_Return'], label='Buy and Hold')\n",
    "plt.plot(aapl_features_clean['Date'], aapl_features_clean['Strategy_Cumulative_Return'], label='ML Strategy')\n",
    "plt.title('Cumulative Returns: Buy and Hold vs ML Strategy')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate performance metrics\n",
    "buy_hold_return = aapl_features_clean['Actual_Cumulative_Return'].iloc[-1]\n",
    "strategy_return = aapl_features_clean['Strategy_Cumulative_Return'].iloc[-1]\n",
    "\n",
    "print(f\"Buy and Hold Return: {buy_hold_return:.2%}\")\n",
    "print(f\"ML Strategy Return: {strategy_return:.2%}\")\n",
    "print(f\"Outperformance: {strategy_return - buy_hold_return:.2%}\")\n",
    "```\n",
    "\n",
    "## 9. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've built a machine learning model to predict stock price movements using technical indicators. Our model achieved [accuracy] accuracy in predicting next-day price movements for Apple stock.\n",
    "\n",
    "Key findings:\n",
    "1. Technical indicators like [top features] were most predictive\n",
    "2. The optimized model parameters were [best parameters]\n",
    "3. Our trading strategy [outperformed/underperformed] a simple buy-and-hold approach\n",
    "\n",
    "Next steps for improvement:\n",
    "1. Incorporate more data sources (e.g., sentiment analysis, macroeconomic indicators)\n",
    "2. Experiment with different machine learning algorithms\n",
    "3. Implement more sophisticated trading strategies\n",
    "4. Test the model on different stocks and time periods\n",
    "5. Consider time-series specific approaches like LSTM networks\n",
    "\n",
    "Remember that past performance does not guarantee future results, and this model should be considered for educational purposes only.\n",
    "```python\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Fetch historical stock data\n",
    "def fetch_stock_data(ticker='AAPL', period='5y', interval='1d'):\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    data = yf.download(ticker, period=period, interval=interval)\n",
    "    return data.reset_index()\n",
    "\n",
    "# Example: Fetch Apple stock data for the past 5 years\n",
    "aapl_data = fetch_stock_data('AAPL', '5y', '1d')\n",
    "\n",
    "# Display the first few rows\n",
    "aapl_data.head()\n",
    "```\n",
    "\n",
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Let's explore the data to understand the stock's price history.\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
